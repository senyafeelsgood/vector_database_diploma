{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Диплом данные.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Имяфайла</th>\n",
       "      <th>Раса</th>\n",
       "      <th>Цвет глаз</th>\n",
       "      <th>Цвет волос</th>\n",
       "      <th>Конституция</th>\n",
       "      <th>Точный возраст</th>\n",
       "      <th>Настроение</th>\n",
       "      <th>Волосы длинные</th>\n",
       "      <th>Солнцезащитные очки</th>\n",
       "      <th>Кудрявые волосы</th>\n",
       "      <th>Носатая</th>\n",
       "      <th>Обычные очки</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66002.png</td>\n",
       "      <td>европеоидная</td>\n",
       "      <td>карие</td>\n",
       "      <td>каштановые</td>\n",
       "      <td>обычная</td>\n",
       "      <td>25</td>\n",
       "      <td>веселое</td>\n",
       "      <td>да</td>\n",
       "      <td>нет</td>\n",
       "      <td>да</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66017.png</td>\n",
       "      <td>азиатская</td>\n",
       "      <td>карие</td>\n",
       "      <td>черные</td>\n",
       "      <td>худая</td>\n",
       "      <td>28</td>\n",
       "      <td>нейтральная</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66023.png</td>\n",
       "      <td>латиноамериканская</td>\n",
       "      <td>карие</td>\n",
       "      <td>каштановые</td>\n",
       "      <td>худая</td>\n",
       "      <td>18</td>\n",
       "      <td>нейтральная</td>\n",
       "      <td>да</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66042.png</td>\n",
       "      <td>европеоидная</td>\n",
       "      <td>карие</td>\n",
       "      <td>русые</td>\n",
       "      <td>обычная</td>\n",
       "      <td>24</td>\n",
       "      <td>веселое</td>\n",
       "      <td>да</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66053.png</td>\n",
       "      <td>европеоидная</td>\n",
       "      <td>карие</td>\n",
       "      <td>русые</td>\n",
       "      <td>обычная</td>\n",
       "      <td>23</td>\n",
       "      <td>веселое</td>\n",
       "      <td>да</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "      <td>нет</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Имяфайла                Раса Цвет глаз  Цвет волос Конституция  \\\n",
       "0  66002.png        европеоидная     карие  каштановые     обычная   \n",
       "1  66017.png           азиатская     карие      черные       худая   \n",
       "2  66023.png  латиноамериканская     карие  каштановые       худая   \n",
       "3  66042.png        европеоидная     карие       русые     обычная   \n",
       "4  66053.png        европеоидная     карие       русые     обычная   \n",
       "\n",
       "   Точный возраст   Настроение Волосы длинные Солнцезащитные очки  \\\n",
       "0              25      веселое             да                 нет   \n",
       "1              28  нейтральная            нет                 нет   \n",
       "2              18  нейтральная             да                 нет   \n",
       "3              24      веселое             да                 нет   \n",
       "4              23      веселое             да                 нет   \n",
       "\n",
       "  Кудрявые волосы Носатая Обычные очки  \n",
       "0              да     нет          нет  \n",
       "1             нет     нет          нет  \n",
       "2             нет     нет          нет  \n",
       "3             нет     нет          нет  \n",
       "4             нет     нет          нет  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['европеоидная' 'азиатская' 'латиноамериканская' 'африканская']\n"
     ]
    }
   ],
   "source": [
    "print(data['Раса'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Раса\"] == 'африканская'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['карие' 'зеленые' 'голубые' 'не видно']\n"
     ]
    }
   ],
   "source": [
    "print(data['Цвет глаз'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['каштановые' 'черные' 'русые' 'блонд' 'рыжие']\n"
     ]
    }
   ],
   "source": [
    "print(data['Цвет волос'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['обычная' 'худая' 'полная']\n"
     ]
    }
   ],
   "source": [
    "print(data['Конституция'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['веселое' 'нейтральная']\n"
     ]
    }
   ],
   "source": [
    "print(data['Настроение'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Путь к папке с изображениями\n",
    "images_folder = 'data_diploma_images'\n",
    "image_paths = [os.path.join(images_folder, img) for img in os.listdir(images_folder) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arcface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "import cv2\n",
    "\n",
    "app = FaceAnalysis(name=\"buffalo_l\", providers=['CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0)\n",
    "\n",
    "app.det_thresh = 0\n",
    "\n",
    "embeddings_arcface = []\n",
    "pictures_arcface = []\n",
    "\n",
    "for path in tqdm(image_paths):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    faces = app.get(img)\n",
    "    if faces:\n",
    "        emb = faces[0].embedding\n",
    "        embeddings_arcface.append(emb)\n",
    "\n",
    "        pictures_arcface.append(path)\n",
    "    else:\n",
    "        print(f\"Лицо не найдено на изображении: {path}\")\n",
    "\n",
    "\n",
    "# Сохраняем все эмбеддинги\n",
    "embeddings_arcface = np.vstack(embeddings_arcface)\n",
    "np.save('embeddings_arcface.npy', embeddings_arcface)\n",
    "\n",
    "print(f\"Эмбеддинги сохранены в файл embeddings_arcface.npy. Размер: {embeddings_arcface.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    }
   ],
   "source": [
    "# print()\n",
    "print(len(pictures_arcface))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:14<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмбеддинги сохранены в файл embeddings_clip.npy. Размер: (500, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "import certifi\n",
    "import clip\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Настроим SSL контекст с certifi для корректной загрузки модели через HTTPS\n",
    "ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "\n",
    "# Используем стандартный urlopen с новым SSL контекстом\n",
    "original_urlopen = urllib.request.urlopen\n",
    "urllib.request.urlopen = lambda *args, **kwargs: original_urlopen(*args, context=ssl_context, **kwargs)\n",
    "\n",
    "# Загружаем модель CLIP\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "\n",
    "embeddings_clip = []\n",
    "pictures_clip = []\n",
    "\n",
    "for path in tqdm(image_paths):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    img_tensor = preprocess(img).unsqueeze(0).to(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        emb = model.encode_image(img_tensor).squeeze().cpu().numpy()  # Переходим на CPU для сохранения данных\n",
    "    embeddings_clip.append(emb)\n",
    "    pictures_clip.append(path)\n",
    "\n",
    "# Сохраняем все эмбеддинги в файл\n",
    "embeddings_clip = np.vstack(embeddings_clip)\n",
    "np.save('embeddings_clip.npy', embeddings_clip)\n",
    "\n",
    "print(f\"Эмбеддинги сохранены в файл embeddings_clip.npy. Размер: {embeddings_clip.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DLIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "shape_predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "face_rec_model = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\n",
    "\n",
    "for path in tqdm(image_paths):\n",
    "    img = cv2.imread(path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    faces = detector(img_rgb)\n",
    "    if faces:\n",
    "        shape = shape_predictor(img_rgb, faces[0])\n",
    "        emb = face_rec_model.compute_face_descriptor(img_rgb, shape)\n",
    "        embeddings.append(np.array(emb))\n",
    "    else:\n",
    "        print(f\"Лицо не найдено на изображении: {path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FACENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import InceptionResnetV1\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "for path in tqdm(image_paths):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    img_tensor = preprocess(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        emb = model(img_tensor).squeeze().numpy()\n",
    "    embeddings.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QDRANT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='embeddings_clip')]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://da29a06c-ee8f-4858-a8a5-19338dc36ef6.eu-central-1-0.aws.cloud.qdrant.io:6333\", \n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.-PPZ8WHcjIkTMVoMcXfZO39Foiku3cbS-BIW05tdKuw\",\n",
    ")\n",
    "\n",
    "print(qdrant_client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_client.delete_collection(collection_name=\"my-embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"embeddings_clip\"\n",
    "\n",
    "qdrant_client.delete_collection(collection_name = collection_name)\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=512,       # Размерность эмбеддингов\n",
    "        distance=Distance.COSINE  # Или EUCLID, DOT — зависит от твоей задачи\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "embeddings = np.load(\"embeddings_clip.npy\")\n",
    "\n",
    "points = [\n",
    "    PointStruct(\n",
    "        id=i,\n",
    "        vector=embeddings[i].tolist(),\n",
    "        payload={\"meta\": f\"item_{i}\"}  # Можно передать метаинформацию\n",
    "    )\n",
    "    for i in range(1,embeddings.shape[0]+1)\n",
    "]\n",
    "\n",
    "qdrant_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points=[ScoredPoint(id=0, version=0, score=1.0000001, payload={'meta': 'item_0'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=456, version=0, score=0.89132935, payload={'meta': 'item_456'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=232, version=0, score=0.885788, payload={'meta': 'item_232'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=372, version=0, score=0.8747232, payload={'meta': 'item_372'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=73, version=0, score=0.8745144, payload={'meta': 'item_73'}, vector=None, shard_key=None, order_value=None)]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "import numpy as np\n",
    "\n",
    "# Пример вектора запроса, который ты хочешь использовать для поиска\n",
    "query_vector = embeddings.tolist()[0]  # Вектор запроса размером 512\n",
    "\n",
    "# Поиск ближайших 5 точек по запросному вектору\n",
    "nearest = qdrant_client.query_points(\n",
    "    collection_name=\"my-embeddings\",  # Название коллекции\n",
    "    query=query_vector,  # Запросный вектор\n",
    "    limit=5,  # Количество ближайших точек\n",
    "    with_payload=True,  # Вернуть метаинформацию\n",
    "    with_vectors=False  # Не возвращать векторы (если они не нужны)\n",
    ")\n",
    "\n",
    "# Вывод результатов поиска\n",
    "print(nearest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рекомендации на основе усреднённых векторов\n",
    "recommended = qdrant_client.query_points(\n",
    "    collection_name=\"my-embeddings\",\n",
    "    query=models.RecommendQuery(\n",
    "        recommend=models.RecommendInput(\n",
    "            positive=[\"43cf51e2-8777-4f52-bc74-c2cbde0c8b04\", [0.11, 0.35, 0.6, ...]],  # Пример положительного вектора\n",
    "            negative=[[0.01, 0.45, 0.67, ...]]  # Пример отрицательного вектора\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Вывод результатов рекомендаций\n",
    "print(\"Recommended points:\")\n",
    "for point in recommended['result']:\n",
    "    print(f\"ID: {point['id']}, Score: {point['score']}, Payload: {point['payload']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фьюжн запрос (гибридный поиск)\n",
    "hybrid = qdrant_client.query_points(\n",
    "    collection_name=\"my-embeddings\",\n",
    "    prefetch=[\n",
    "        models.Prefetch(\n",
    "            query=models.SparseVector(indices=[1, 42], values=[0.22, 0.8]),  # Пример разреженного вектора\n",
    "            using=\"sparse\",\n",
    "            limit=20,\n",
    "        ),\n",
    "        models.Prefetch(\n",
    "            query=[0.01, 0.45, 0.67, ...],  # Пример плотного вектора\n",
    "            using=\"dense\",\n",
    "            limit=20,\n",
    "        ),\n",
    "    ],\n",
    "    query=models.FusionQuery(fusion=models.Fusion.RRF),  # Пример метода фьюжн\n",
    ")\n",
    "\n",
    "# Вывод результатов фьюжн запроса\n",
    "print(\"Hybrid search results:\")\n",
    "for point in hybrid['result']:\n",
    "    print(f\"ID: {point['id']}, Score: {point['score']}, Payload: {point['payload']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
